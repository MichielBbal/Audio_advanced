{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa892f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c2b2207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between \"helicopter\" and \"car\": 0.1089\n",
      "One or both of the words \"helicopter\" and \"airplane\" not found in the vocabulary.\n",
      "One or both of the words \"helicopter\" and \"truck\" not found in the vocabulary.\n",
      "One or both of the words \"helicopter\" and \"tram\" not found in the vocabulary.\n",
      "One or both of the words \"car\" and \"airplane\" not found in the vocabulary.\n",
      "One or both of the words \"car\" and \"truck\" not found in the vocabulary.\n",
      "One or both of the words \"car\" and \"tram\" not found in the vocabulary.\n",
      "One or both of the words \"airplane\" and \"truck\" not found in the vocabulary.\n",
      "One or both of the words \"airplane\" and \"tram\" not found in the vocabulary.\n",
      "One or both of the words \"truck\" and \"tram\" not found in the vocabulary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/michielbontenbal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#source chatgpt\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')  # Download the punkt tokenizer\n",
    "\n",
    "# Sample sentences for training the Word2Vec model\n",
    "sentences = [\n",
    "    'I love to fly a helicopter',\n",
    "    'I drive my car every day',\n",
    "    'Airplanes are fast',\n",
    "    'Trucks transport goods',\n",
    "    'Trams are a form of public transportation',\n",
    "]\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "word_pairs = [('helicopter', 'car'), ('helicopter', 'airplane'), ('helicopter', 'truck'),\n",
    "              ('helicopter', 'tram'), ('car', 'airplane'), ('car', 'truck'), ('car', 'tram'),\n",
    "              ('airplane', 'truck'), ('airplane', 'tram'), ('truck', 'tram')]\n",
    "\n",
    "for word1, word2 in word_pairs:\n",
    "    if word1 in model.wv and word2 in model.wv:\n",
    "        embedding1 = model.wv[word1].reshape(1, -1)\n",
    "        embedding2 = model.wv[word2].reshape(1, -1)\n",
    "        similarity = cosine_similarity(embedding1, embedding2)[0, 0]\n",
    "        print(f'Cosine Similarity between \"{word1}\" and \"{word2}\": {similarity:.4f}')\n",
    "    else:\n",
    "        print(f'One or both of the words \"{word1}\" and \"{word2}\" not found in the vocabulary.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d614f82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8a3d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2bf2d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ashraq/esc50\")\n",
    "categories = dataset['train']['category'] #get all categories from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70ee0af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "['airplane', 'breathing', 'brushing_teeth', 'can_opening', 'car_horn', 'cat', 'chainsaw', 'chirping_birds', 'church_bells', 'clapping', 'clock_alarm', 'clock_tick', 'coughing', 'cow', 'crackling_fire', 'crickets', 'crow', 'crying_baby', 'dog', 'door_wood_creaks', 'door_wood_knock', 'drinking_sipping', 'engine', 'fireworks', 'footsteps', 'frog', 'glass_breaking', 'hand_saw', 'helicopter', 'hen', 'insects', 'keyboard_typing', 'laughing', 'mouse_click', 'pig', 'pouring_water', 'rain', 'rooster', 'sea_waves', 'sheep', 'siren', 'sneezing', 'snoring', 'thunderstorm', 'toilet_flush', 'train', 'vacuum_cleaner', 'washing_machine', 'water_drops', 'wind']\n"
     ]
    }
   ],
   "source": [
    "#get the unique categories, sort them and print them\n",
    "unique_categories = set(categories)\n",
    "categories = list(unique_categories)\n",
    "categories = sorted(categories)\n",
    "\n",
    "print(len(categories))\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea660a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airco', 'airplane', 'beep of car', 'bell of tram', 'bird', 'car door', 'car_truck', 'clapping', 'claxon', 'construction', 'crowd', 'cyclist', 'dog', 'ferry', 'festival', 'footsteps', 'gunshot', 'helicopter', 'jackhammer', 'loading truck', 'music', 'piling', 'rail', 'raindrop', 'roll container', 'scooter/moped', 'shouting', 'silence', 'singing', 'siren', 'slamming door', 'talking', 'thunder', 'whistling', 'wind']\n"
     ]
    }
   ],
   "source": [
    "#we've created the following sound labels\n",
    "urban_sound_labels = [\"bird\", \"dog\", \"thunder\", \"wind\", \"raindrop\", \"scooter/moped\", \"car_truck\", 'cyclist', 'airplane', 'helicopter', 'rail', 'ferry', 'beep of car', \"car door\", 'claxon', 'bell of tram', 'siren', 'talking', 'shouting', 'clapping', 'footsteps', 'crowd', 'singing', 'whistling', 'festival', 'music', 'roll container', 'loading truck', 'jackhammer', 'piling', 'construction', 'airco', 'slamming door', 'silence', 'gunshot']\n",
    "print(sorted(urban_sound_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78cd294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_list_from_categories= ['airplane', 'car_horn', 'chirping_birds', 'clapping', 'dog', 'engine', 'helicopter', 'rain', 'siren', 'thunderstorm','train', 'wind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085a5e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do\n",
    "tuples_list = [('airplane', 'airplane'),('car_horn', 'claxon'), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40b19f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentences\n",
    "tokenized_categories = [word_tokenize(category.lower()) for category in categories]\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=tokenized_categories, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e333f3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.3622725e-04,  2.3643136e-04,  5.1033497e-03,  9.0092728e-03,\n",
       "       -9.3029495e-03, -7.1168090e-03,  6.4588725e-03,  8.9729885e-03,\n",
       "       -5.0154282e-03, -3.7633716e-03,  7.3805046e-03, -1.5334714e-03,\n",
       "       -4.5366134e-03,  6.5540518e-03, -4.8601604e-03, -1.8160177e-03,\n",
       "        2.8765798e-03,  9.9187379e-04, -8.2852151e-03, -9.4488179e-03,\n",
       "        7.3117660e-03,  5.0702621e-03,  6.7576934e-03,  7.6286553e-04,\n",
       "        6.3508903e-03, -3.4053659e-03, -9.4640139e-04,  5.7685734e-03,\n",
       "       -7.5216377e-03, -3.9361035e-03, -7.5115822e-03, -9.3004224e-04,\n",
       "        9.5381187e-03, -7.3191668e-03, -2.3337686e-03, -1.9377411e-03,\n",
       "        8.0774371e-03, -5.9308959e-03,  4.5162440e-05, -4.7537340e-03,\n",
       "       -9.6035507e-03,  5.0072931e-03, -8.7595852e-03, -4.3918253e-03,\n",
       "       -3.5099984e-05, -2.9618145e-04, -7.6612402e-03,  9.6147433e-03,\n",
       "        4.9820580e-03,  9.2331432e-03, -8.1579173e-03,  4.4957981e-03,\n",
       "       -4.1370760e-03,  8.2453608e-04,  8.4986202e-03, -4.4621765e-03,\n",
       "        4.5175003e-03, -6.7869602e-03, -3.5484887e-03,  9.3985079e-03,\n",
       "       -1.5776526e-03,  3.2137157e-04, -4.1406299e-03, -7.6826881e-03,\n",
       "       -1.5080082e-03,  2.4697948e-03, -8.8802696e-04,  5.5336617e-03,\n",
       "       -2.7429771e-03,  2.2600652e-03,  5.4557943e-03,  8.3459532e-03,\n",
       "       -1.4537406e-03, -9.2081428e-03,  4.3705525e-03,  5.7178497e-04,\n",
       "        7.4419081e-03, -8.1328274e-04, -2.6384138e-03, -8.7530091e-03,\n",
       "       -8.5655687e-04,  2.8265631e-03,  5.4014288e-03,  7.0526563e-03,\n",
       "       -5.7031214e-03,  1.8588197e-03,  6.0888636e-03, -4.7980510e-03,\n",
       "       -3.1072604e-03,  6.7976294e-03,  1.6314756e-03,  1.8991709e-04,\n",
       "        3.4736372e-03,  2.1777749e-04,  9.6188262e-03,  5.0606038e-03,\n",
       "       -8.9173904e-03, -7.0415605e-03,  9.0145587e-04,  6.3925339e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd417cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bird', 'airplane'), ('Bird', 'breathing'), ('Bird', 'brushing_teeth'), ('Bird', 'can_opening'), ('Bird', 'car_horn'), ('Bird', 'cat'), ('Bird', 'chainsaw'), ('Bird', 'chirping_birds'), ('Bird', 'church_bells'), ('Bird', 'clapping')]\n",
      "1750\n"
     ]
    }
   ],
   "source": [
    "#create tuples from items in the two lists\n",
    "from itertools import product\n",
    "\n",
    "# Create tuples for all combinations\n",
    "word_pairs = list(product(urban_sound_labels, categories))\n",
    "\n",
    "print(word_pairs[:10])\n",
    "print(len(word_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d27da290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One or both of the words \"Bird\" and \"airplane\" not found in the vocabulary.\n",
      "One or both of the words \"Bird\" and \"breathing\" not found in the vocabulary.\n",
      "One or both of the words \"Bird\" and \"brushing_teeth\" not found in the vocabulary.\n",
      "One or both of the words \"Bird\" and \"can_opening\" not found in the vocabulary.\n",
      "One or both of the words \"Bird\" and \"car_horn\" not found in the vocabulary.\n",
      "One or both of the words \"Bird\" and \"cat\" not found in the vocabulary.\n",
      "One or both of the words \"Bird\" and \"chainsaw\" not found in the vocabulary.\n",
      "One or both of the words \"Bird\" and \"chirping_birds\" not found in the vocabulary.\n",
      "One or both of the words \"Bird\" and \"church_bells\" not found in the vocabulary.\n",
      "One or both of the words \"Bird\" and \"clapping\" not found in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "for word1, word2 in word_pairs[:10]:\n",
    "    if word1 in model.wv and word2 in model.wv:\n",
    "        embedding1 = model.wv[word1].reshape(1, -1)\n",
    "        print(embedding1)\n",
    "        embedding2 = model.wv[word2].reshape(1, -1)\n",
    "        similarity = cosine_similarity(embedding1, embedding2)[0, 0]\n",
    "        print(f'Cosine Similarity between \"{word1}\" and \"{word2}\": {similarity:.4f}')\n",
    "    else:\n",
    "        print(f'One or both of the words \"{word1}\" and \"{word2}\" not found in the vocabulary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e257c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d07406f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b2259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed22f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9326e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eac53f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0e742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1a36ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48865118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
